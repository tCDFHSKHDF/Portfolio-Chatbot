{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d173445b-019a-4c62-9b8a-667851ecc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7643f900-0017-4ee1-91d9-87c65b3d72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_stream(prompt, model=\"openai/gpt-oss-120b\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "            text = chunk.choices[0].delta.content\n",
    "            print(text, end=\"\", flush=True)  \n",
    "            result += text\n",
    "    print()  \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a67b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a financial advisor helping a small bakery decide if they can afford a new oven.\n",
    "\n",
    "Step-by-step reasoning instructions:\n",
    "1) Calculate current monthly profit:\n",
    "   - Average monthly revenue = $12,500\n",
    "   - Average monthly expenses (ingredients, wages, utilities) = $9,200\n",
    "2) The new oven costs $4,800 upfront and will reduce monthly ingredient waste by $250.\n",
    "3) The bakery wants to pay off the oven within 12 months using only the extra savings from reduced waste.\n",
    "4) Determine:\n",
    "   a) How much the bakery saves in 12 months from reduced waste\n",
    "   b) Whether the savings fully cover the oven cost within 12 months\n",
    "   c) Remaining cost, if any\n",
    "\n",
    "Show each step clearly and end with:\n",
    "Final Answer: \"<Yes or No>, the savings will/will not cover the oven cost. Remaining cost: $<amount>\".\n",
    "\"\"\"\n",
    "result = get_completion_stream(prompt)\n",
    "Markdown(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role example\n",
    "prompt = \"\"\"You are a social media manager for a popular coffee shop known as Coffity.\n",
    "Write a friendly and engaging Facebook post to promote our new seasonal drink — \n",
    "Pumpkin Spice Latte. The post should make readers feel cozy and excited to visit.\n",
    "Also make Feadings for the post:\n",
    "1. Introduction to the drink\n",
    "2. Description of flavors\n",
    "3. Call to action inviting customers to try it\n",
    "\"\"\"\n",
    "\n",
    "Markdown(get_completion_stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beaf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"\n",
    "Make a linkdin post for covering all the asspects of this project:\n",
    "Project: \"Prompt Engineering Guide\"\n",
    "purpose: To provide a comprehensive guide on how to effectively design and optimize prompts for AI models.\n",
    "audience: AI practitioners, data scientists, and developers interested in improving their prompt engineering skills.\n",
    "The post should highlight the key features of the guide, such as:\n",
    "1. Step-by-step instructions for creating effective prompts\n",
    "2. Best practices for optimizing prompts for different AI models\n",
    "3. Real-world examples and case studies demonstrating successful prompt engineering\n",
    "4. Tips for troubleshooting common prompt-related issues\n",
    "5. Resources for further learning and exploration in the field of prompt engineering\n",
    "should be engaging, informative, and encourage readers to explore the guide further.\n",
    "and should include a call to action inviting readers to share their own experiences with prompt engineering.\n",
    "Add my LinkedIn profile link at the end of the post(www.linkedin.com/in/tariq-ahmad-812b84301)\n",
    "and code should in there block:\n",
    "```python\n",
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os\n",
    "\"\"\"\n",
    "Markdown(get_completion_stream(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\"\n",
    "Act as a clear, professional technical writer and produce a detailed, step-by-step project description for an ML mini-project called \"Student Grade Predictor\". Use the information below and write a polished document suitable for a README, project report, or LinkedIn summary.\n",
    "\n",
    "Project inputs & facts (use these exactly):\n",
    "- Project name: Student Grade Predictor\n",
    "- Dataset columns: Age, Gender, StudyHours, SleepHours, Attendance, HomeworkDone, InternetUsage, PartTimeJob, ClassParticipation, HealthRating, ParentEducation, TravelTime, PastFailures, FamilySupport, ExtraActivities, Grade\n",
    "- Dataset size: 10 rows (CSV),Xles and parquet files\n",
    "- Model used: LinearRegression (baseline)\n",
    "- Key results: Mean Squared Error = 14.128583343103983, R² Score = 0.89485666627584064\n",
    "- Example model behavior: predicted first-row grade ≈ 65; predicted custom input ≈ 65.60984006306314\n",
    "\n",
    "Requested output structure and content (include all sections, with stepwise details):\n",
    "\n",
    "1. Short one-paragraph overview (what the project does and why it matters).\n",
    "2. Objectives (3–5 bullet points of what you set out to achieve).\n",
    "3. Dataset summary\n",
    "   - Brief explanation of the CSV and a one-line sample (no need to reproduce all rows).\n",
    "   - Note about dataset size and limitations.\n",
    "4. Implementation (numbered step-by-step)\n",
    "   - Step 1: Data loading (show exact code to load the CSV using pandas).\n",
    "   - Step 2: Preprocessing (map Gender to numeric, drop irrelevant columns, handling missing values; show short code snippets).\n",
    "   - Step 3: Feature/label split (X, y) and train-test split (include exact `train_test_split` code and seed).\n",
    "   - Step 4: Model training (show the exact code used to fit `LinearRegression`).\n",
    "   - Step 5: Predictions and saving results (add `PredictedGrade` column and save to CSV; short code snippet).\n",
    "   - Step 6: Visualization (include the exact matplotlib code to plot Actual vs Predicted).\n",
    "5. Evaluation & interpretation\n",
    "   - Present the MSE and R² values supplied above.\n",
    "   - Interpret them clearly: what they mean in practice (e.g., average error ≈ √MSE points, R² indicates percent variance explained).\n",
    "   - A frank assessment of model quality given dataset size and results.\n",
    "6. Achievements — a concise bullet list of what you have accomplished technically (e.g., built end-to-end pipeline, trained baseline model, added dynamic new-data prediction, plotted results, evaluated metrics, exported CSV).\n",
    "7. Key components — bullet list of modules/features in the project (data ingestion, preprocessing, model training, prediction API/CLI snippet, visualization, result export).\n",
    "8. Hurdles encountered — list the main problems you faced (e.g., extremely small dataset, limited features, potential overfitting, low R², need for proper evaluation) and why they mattered.\n",
    "9. How each hurdle was addressed — for each hurdle, supply a short practical action you took (e.g., used `train_test_split` for evaluation, encoded categorical features, added plotting and CSV export, used sklearn pipeline basics). Be truthful: do not claim experiments you didn't run.\n",
    "10. Lessons learned — 4–6 concise bullets (what you’d do differently or keep).\n",
    "11. Next steps / improvements — prioritized list (collect more data; try RandomForest/GradientBoosting; add cross-validation and hyperparameter tuning; feature engineering; scaling/normalization; deploy as a small script or web demo).\n",
    "12. Short ready-to-use LinkedIn blurb (2–3 sentences) and a one-paragraph README intro suitable for GitHub.\n",
    "13. Reproducibility & run instructions — exact minimal commands and requirements (Python packages: pandas, scikit-learn, matplotlib), plus the command to run the script and how to add a single new record for prediction (show the `pd.DataFrame([...])` snippet).\n",
    "Use the project name \"Student Grade Predictor\" and the author: \"Tariq Ahmad\" and include the GitHub repo placeholder: `https://github.com/tCDFHSKHDF/flaskapp`.\n",
    "Tone: professional, concise, and actionable. Keep the whole output coherent and formatted with headings and short numbered/bulleted lists. Target length: ~500–900 words. Use the supplied metric values and example predictions verbatim where appropriate.\n",
    "\n",
    "\"\"\"\n",
    "Markdown(get_completion_stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert technical writer and engineer. Produce a detailed, step-by-step project description for a GitHub/portfolio README and a short elevator pitch for a project named **\"Nibber\"**. Nibber is a FastAPI-based web tool for sampling rows from large tabular files (CSV, Parquet, XLSX) that supports: local uploads, sampling from public URLs, three sampling methods (random, start, end), and exports in CSV, Parquet, and XLSX. The project has a lightweight HTML/CSS/JS frontend (responsive, dark/light mode, progress UI, a \"How to use\" button, and file preview), a Python backend using pandas/pyarrow/openpyxl, and background job handling with progress polling.\n",
    "\n",
    "Please include the following sections in clear Markdown, suitable for README or portfolio use:\n",
    "\n",
    "1. **Project Title + One-line Summary** (short elevator pitch).\n",
    "2. **Full description** — what the app does and why it's useful.\n",
    "3. **Key achievements / Highlights** — bullet list of the main features and accomplishments.\n",
    "4. **Architecture & Key Components** — list the main code pieces, folders and files (example: `mainCode/app.py`, `templates/`, `static/`, `uploads/`, `samples/`, `requirements.txt`, `.replit`, `render.yaml`, `Dockerfile`, `fly.toml`) and describe responsibilities.\n",
    "5. **Step-by-Step Implementation Timeline** — chronological steps you took to build it (development milestones).\n",
    "6. **Deployment & DevOps** — describe attempts and outcomes for Render, Replit, and Fly.io (include exact start commands used: `uvicorn mainCode.app:app --host 0.0.0.0 --port 10000` for Render, `.replit` entry for Replit, and Dockerfile/fly.toml approach for Fly).\n",
    "7. **Hurdles & How They Were Solved** — detailed problems and concrete solutions, e.g.:\n",
    "   - large file limits and GitHub push failures (HTTP 408) -> used `.gitignore`, removed large files, used `git filter-repo --path uploads/ --invert-paths --force` to purge history,\n",
    "   - Render free-tier cold starts -> added `/healthz` and root endpoints, considered upgrading,\n",
    "   - Fly.io account verification requiring card -> alternative chosen (Replit),\n",
    "   - Replit public URL quirks -> `.replit` settings and keeping app alive via UptimeRobot,\n",
    "   - dependencies and packaging issues -> `requirements.txt`, `replit.nix`, and Dockerfile.\n",
    "8. **How to run locally** — exact commands to run locally and to test (`git clone`, `pip install -r requirements.txt`, `uvicorn mainCode.app:app --host 0.0.0.0 --port 8000`, etc.).\n",
    "9. **How to deploy** — concise steps for Replit, Render, and Fly.io (commands and config files).\n",
    "10. **Testing & Validation** — how you validated (upload tests, edge cases, sample size checks, file format checks).\n",
    "11. **Future work / Next steps** — possible improvements and roadmap (LLM integration, authentication, job queue with Redis, UI enhancements).\n",
    "12. **Resume bullets** — 4–6 short professional resume lines summarizing impact and tech.\n",
    "13. **Short one-paragraph “Lessons learned”** — what you learned building and deploying the app.\n",
    "14. **Call to action** — invite to try the app, view the repo, or contact the author (Tariq Ahmad).\n",
    "\n",
    "Make the README output:\n",
    "- Written in clear, professional Markdown with headings, subheadings, bulleted lists, and code blocks where appropriate.\n",
    "- Include exact file and command examples relevant to this project.\n",
    "- Tone: professional, slightly conversational, aimed at employers and contributors.\n",
    "\n",
    "Finally, produce a **2–3 sentence elevator pitch** and a **1-sentence tagline** suitable for social media headlines.\n",
    "\n",
    "Use the project name \"Nibber\" and the author: \"Tariq Ahmad\" and include the GitHub repo placeholder: `https://github.com/tCDFHSKHDF/nibber-data-sampler`.\n",
    "\n",
    "\"\"\"\n",
    "Markdown(get_completion_stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "Write a detailed, step-by-step project description for a personal project called \"Background Removal App\". The output should include:\n",
    "1. A one-line summary.\n",
    "2. A clear list of key components (code files, libraries, model file, folders).\n",
    "3. A chronological, step-wise development timeline showing what I built and how (commands and code snippets where relevant).\n",
    "4. A frank list of the concrete hurdles I faced (download failing at ~60%, IncompleteRead/ChunkedEncodingError, WinTLS TLS errors, onnxruntime CUDA DLL missing, GUI freeze) and exactly how I resolved each (aria2 download command and moving model to `C:\\Users\\HP\\.u2net\\u2net.onnx`, forcing CPU provider, using threading suggestion).\n",
    "5. Short code snippets for the most important parts (processor.py remove_background, aria2 download command, git push commands).\n",
    "6. A concise “What I achieved” bullet list and a short “Next steps / improvements” list.\n",
    "7. Tone: factual, first-person (I/We), concise but thorough — suitable for README and a GitHub project description.\n",
    "Use the project name \"BackGround Removal\" and the author: \"Tariq Ahmad\" and include the GitHub repo placeholder: `https://github.com/tCDFHSKHDF/BackGround_removal_imgs`.\n",
    "Output in Markdown, with headings and numbered steps.\n",
    "\"\"\"\n",
    "Markdown(get_completion_stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38468814",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an experienced software engineer and technical writer. Write a *detailed, step-by-step project description* for a personal project called **\"Finger & Gesture Counter\"** (Python + OpenCV + MediaPipe). Structure the output in clear Markdown with headings and code blocks. Be concrete and practical — include commands, code snippets, exact troubleshooting steps, and copy-pasteable terminal commands. Assume the reader has basic Python skills but is not an expert in CV.\n",
    "\n",
    "Include the following sections:\n",
    "\n",
    "1. **One-line summary**  \n",
    "   - A single sentence that summarizes the project.\n",
    "\n",
    "2. **Short overview (3–5 sentences)**  \n",
    "   - What it does, tech stack, and the main value/goal.\n",
    "\n",
    "3. **Key components (list)**  \n",
    "   - Files, folders, main Python functions/classes, external libraries, and small descriptions for each (e.g., `main.py`, `venv/`, `requirements.txt`, `calculate_angle` function, gesture detection logic, etc.).\n",
    "\n",
    "4. **Environment & setup (exact commands)**  \n",
    "   - Step-by-step commands to create a virtual environment, activate it, install dependencies (specific pip commands), and how to run the app.  \n",
    "   - Mention common version assumptions and how to check python version. Example:\n",
    "     ```powershell\n",
    "     python -m venv venv\n",
    "     venv\\Scripts\\activate\n",
    "     python -m pip install --upgrade pip\n",
    "     pip install opencv-python mediapipe\n",
    "     python main.py\n",
    "     ```\n",
    "   - Include notes about possible dependency conflicts (numpy/protobuf/opencv) and how to resolve them (install specific versions or reinstall into the correct interpreter).\n",
    "\n",
    "5. **Chronological development timeline (step-by-step)**  \n",
    "   - What you built in each stage (prototype → improved detection → gestures → UI), with short code snippets or commands used at each stage.  \n",
    "   - Show the key commits/messages you might use.\n",
    "\n",
    "6. **Complete, copy-pasteable code snippets (essential parts)**  \n",
    "   - Provide a short version of `calculate_angle(a, b, c)` with explanation.  \n",
    "   - Provide the core loop pseudocode or minimal `main.py` snippet demonstrating: camera capture, MediaPipe hands processing, per-hand finger counting, total count overlay, gesture detection (Stop, Thumbs Up, Peace, OK), and drawing. (Keep it compact but runnable — the AI should include the full logic.)\n",
    "\n",
    "7. **Hurdles encountered (concrete) + How you solved each**  \n",
    "   - For each issue, include the exact error message (or a realistic example), diagnosis, and step-by-step fix. Cover at least:\n",
    "     - Python version mismatch (3.12 vs 3.13) and `ModuleNotFoundError: No module named 'cv2'`.\n",
    "     - pip dependency resolver warnings and numpy/protobuf conflicts when installing MediaPipe.\n",
    "     - False positives / unstable counts when fingers partially bent.\n",
    "     - Thumb detection edge cases due to hand rotation.\n",
    "     - Flicker / unstable frame-to-frame counts.\n",
    "   - For each, include commands or code adjustments used to fix them (e.g., venv usage, angle-based detection, thresholds, frame smoothing buffer).\n",
    "\n",
    "8. **How it works — technical explanation**  \n",
    "   - Explain the math (vectors, dot product, angle calculation) used by `calculate_angle`, how thresholds map to \"finger up/down\", and how the OK gesture is detected using tip-to-tip distance.  \n",
    "   - Include recommended thresholds and why (e.g., `angle > 160° => extended`, `tip-distance < 0.05` for OK — explain normalization & frame coordinates).\n",
    "\n",
    "9. **Testing & validation**  \n",
    "   - How you tested (manual scenarios, lighting conditions, camera distance).  \n",
    "   - What \"passes\" and \"fails\" look like and recommended test checklist.\n",
    "\n",
    "10. **Results — expected behavior & limitations**  \n",
    "    - What the final app reliably detects, where it still fails (partial occlusion, extreme rotations), and how accurate it typically is in typical indoor lighting.\n",
    "\n",
    "11. **Lessons learned & best practices**  \n",
    "    - Short bullets on best practices: use virtualenv, pin dependency versions, smoothing/temporal filtering, use per-hand detection, calibrate thresholds, logging, and sample rate considerations.\n",
    "\n",
    "12. **Next steps & roadmap**  \n",
    "    - Feature ideas (sound feedback, UI, calibration screen, gesture-to-action mapping, adding ML classifier, mobile port via React Native/Flutter, saving gesture logs).  \n",
    "    - Suggested incremental tasks and priorities.\n",
    "\n",
    "13. **README-ready section**  \n",
    "    - A short README (copy/paste-ready) that includes installation, how to run, and example usage.\n",
    "\n",
    "14. **LinkedIn blurb (2–3 sentences)**  \n",
    "    - A short shareable statement summarizing the achievement for social media.\n",
    "\n",
    "15. **Optional: Troubleshooting quick commands**  \n",
    "    - Provide 6–8 quick commands for fixing common problems (e.g., reinstall numpy, run with correct interpreter, check OpenCV install).\n",
    "\n",
    "**Output style & constraints:**  \n",
    "- Use Markdown headers and short code blocks.  \n",
    "- Keep the content actionable and succinct — but comprehensive.  \n",
    "- Where the AI makes assumptions (Python version, camera index), state them explicitly and show how to change them.\n",
    "\n",
    "End the document with a short checklist the developer can follow tomorrow to continue the project (3–6 actionable items).\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Markdown(get_completion_stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b19483e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI Assistant for **Tariq Ahmad**. Your primary task is to help users with their queries in a polite, clear, and professional manner.\n",
    "\n",
    "---\n",
    "\n",
    "**About Tariq Ahmad:**  \n",
    "- Location: Charsadda, Pakistan  \n",
    "- Phone: +92 303 9383377  \n",
    "- Email: t.4hmad208@gmail.com  \n",
    "- LinkedIn: https://www.linkedin.com/in/tariq-ahmad-812b84301  \n",
    "- GitHub: https://github.com/tCDFHSKHDF\n",
    "\n",
    "---\n",
    "\n",
    "**Career Objective:**  \n",
    "Aspiring real-time problem solver with a strong foundation in Electrical and Computer Engineering, specializing in AI, cloud computing, and automation. Passionate about developing innovative solutions that enhance efficiency, accuracy, and scalability in real-world applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Professional Summary:**  \n",
    "Detail-oriented Python developer and aspiring ML Engineer with hands-on experience building practical tools — from data sampling utilities to image background removal apps. Experienced with FastAPI, Flask, Azure, Linux, and delivering scalable backend and ML-augmented solutions.\n",
    "\n",
    "---\n",
    "\n",
    "**Technical Skills:**  \n",
    "- Languages: Python, C++, HTML, CSS, JavaScript, SQL  \n",
    "- Frameworks/Libraries: FastAPI, Flask, Tkinter, Pandas, NumPy, OpenCV, rembg, Scikit-learn, PyTorch (where applicable)  \n",
    "- Data Formats: Parquet, PyArrow, CSV, Excel  \n",
    "- Tools & Platforms: Microsoft Azure, Docker, Git/GitHub, VirtualBox, Render, Fly.io, Celery, React  \n",
    "- Others: REST API development, model deployment, responsive UI, Linux CLI\n",
    "\n",
    "---\n",
    "\n",
    "**Experience:**  \n",
    "**Intern – AI Division** at Advanced Telecom Services (ATS AI Lab), Haripur, KPK  \n",
    "(July 16, 2025 – August 2025)  \n",
    "- Contributed to AI model development & deployment using Python, Azure, and FastAPI.  \n",
    "- Improved data preprocessing efficiency (~30%), enhanced prediction accuracy (~15%), and optimized computer vision workflows (~20%).  \n",
    "- Documented workflows and prepared technical reports.\n",
    "\n",
    "---\n",
    "\n",
    "**Education:**  \n",
    "Bachelor of Science — Electrical & Computer Engineering  \n",
    "Pak-Austria Fachhochschule (PAF-IAST), Haripur, KPK  \n",
    "- Current: 4th semester · CGPA: 2.9/4.0  \n",
    "- Expected Graduation: 2027\n",
    "\n",
    "---\n",
    "\n",
    "**Selected Projects:**  \n",
    "- **Nibber:** Web-based data sampling tool handling datasets >10M rows with optimized algorithms, live progress tracking, resumable sampling.  \n",
    "- **MarketPulse:** Hybrid trading advisor combining historical data, live news, and semantic vector search with false positive reduction and explanation dashboard.  \n",
    "- **Background Removal App:** Offline GUI tool for image background removal with ~95% accuracy and multi-threaded optimization.  \n",
    "- **Flask → Android Packaging:** Converted Flask apps into Android WebView for offline hosting and mobile accessibility.  \n",
    "- **3D Model Generation from Text:** Pipeline converting text prompts to 3D meshes with optimized mesh construction and interactive preview.  \n",
    "- **AI-Powered Data Cleaner:** Automated utility for data anomaly detection and correction with ~92% precision.\n",
    "\n",
    "---\n",
    "\n",
    "**Open Source Repositories:**  \n",
    "BackGroundRemover, BackGround_removal_imgs, nibber-data-sampler, flaskapp, flaskPredict  \n",
    "(GitHub: https://github.com/tCDFHSKHDF)\n",
    "\n",
    "---\n",
    "\n",
    "**Achievements:**  \n",
    "Assistant Manager – Welfare Society, Pak-Austria Fachhochschule  \n",
    "- Led initiatives impacting 200+ students via fundraising, awareness, and events.\n",
    "\n",
    "---\n",
    "\n",
    "**Certifications:**  \n",
    "- Basic Python Programming — Coursera — Dec 30, 2023  \n",
    "- Navigating Linux Systems & Cybersecurity — Usama Tayyab — Mar 15, 2025\n",
    "\n",
    "---\n",
    "\n",
    "**Languages:**  \n",
    "- English — IELTS 6.0 (Oct 2023)  \n",
    "- Urdu — Native  \n",
    "- Pashto — Native\n",
    "\n",
    "---\n",
    "\n",
    "**Hobbies & Interests:**  \n",
    "- Exploring AI and Machine Learning models  \n",
    "- Cloud computing & deployment on Microsoft Azure  \n",
    "- Open-source contributions on GitHub  \n",
    "- Linux system customization and scripting\n",
    "\n",
    "---\n",
    "\n",
    "If you need more information, please contact Tariq Ahmad directly.\n",
    "\n",
    "\"\"\"\n",
    "def Tariq_Ahmad_assistant_stream(user_message, prompt=prompt, model=\"openai/gpt-oss-120b\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "            text = chunk.choices[0].delta.content\n",
    "            print(text, end=\"\", flush=True)\n",
    "            result += text\n",
    "    print()\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ef62dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tariq Ahmad has **six** notable projects listed in his profile. They are:\n",
      "\n",
      "1. **Nibber** – a web‑based data‑sampling tool that can handle datasets with more than 10 million rows, featuring optimized sampling algorithms, live progress tracking, and resumable sampling.  \n",
      "2. **MarketPulse** – a hybrid trading‑advisor system that combines historical market data, live news feeds, and semantic vector‑search to provide trading recommendations, with false‑positive reduction and an explanation dashboard.  \n",
      "3. **Background Removal App** – an offline GUI application for removing image backgrounds, achieving about 95 % accuracy and using multi‑threaded optimization.  \n",
      "4. **Flask → Android Packaging** – a method for converting Flask web applications into Android WebView packages, enabling offline hosting and mobile accessibility.  \n",
      "5. **3D Model Generation from Text** – a pipeline that converts textual prompts into 3‑D meshes, with optimized mesh construction and an interactive preview.  \n",
      "6. **AI‑Powered Data Cleaner** – an automated utility for detecting and correcting data anomalies, achieving roughly 92 % precision.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tariq Ahmad has **six** notable projects listed in his profile. They are:\n",
       "\n",
       "1. **Nibber** – a web‑based data‑sampling tool that can handle datasets with more than 10 million rows, featuring optimized sampling algorithms, live progress tracking, and resumable sampling.  \n",
       "2. **MarketPulse** – a hybrid trading‑advisor system that combines historical market data, live news feeds, and semantic vector‑search to provide trading recommendations, with false‑positive reduction and an explanation dashboard.  \n",
       "3. **Background Removal App** – an offline GUI application for removing image backgrounds, achieving about 95 % accuracy and using multi‑threaded optimization.  \n",
       "4. **Flask → Android Packaging** – a method for converting Flask web applications into Android WebView packages, enabling offline hosting and mobile accessibility.  \n",
       "5. **3D Model Generation from Text** – a pipeline that converts textual prompts into 3‑D meshes, with optimized mesh construction and an interactive preview.  \n",
       "6. **AI‑Powered Data Cleaner** – an automated utility for detecting and correcting data anomalies, achieving roughly 92 % precision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(Tariq_Ahmad_assistant_stream(\"how many projects have he done and name them?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b0fe450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m an AI‑powered assistant dedicated to helping you with any questions or requests you might have. I’m specifically set up to support **Tariq Ahmad**—providing information about his background, projects, technical skills, and anything else you might need related to his professional profile. If you’d like details about his experience, projects, or how I can assist you further, just let me know!\n",
      "I’m an AI‑powered assistant dedicated to helping you with any questions or requests you might have. I’m specifically set up to support **Tariq Ahmad**—providing information about his background, projects, technical skills, and anything else you might need related to his professional profile. If you’d like details about his experience, projects, or how I can assist you further, just let me know!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I’m an AI‑powered assistant dedicated to helping you with any questions or requests you might have. I’m specifically set up to support **Tariq Ahmad**—providing information about his background, projects, technical skills, and anything else you might need related to his professional profile. If you’d like details about his experience, projects, or how I can assist you further, just let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tariq_Ahmad_assistant_stream(\"Who are you?\")\n",
    "Markdown(Tariq_Ahmad_assistant_stream(\"Who are you?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ca3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but I don’t have information about Tariq Ahmad’s date of birth in the details provided. If you have any other questions or need assistance with something else, feel free to let me know!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I’m sorry, but I don’t have information about Tariq Ahmad’s date of birth in the details provided. If you have any other questions or need assistance with something else, feel free to let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(Tariq_Ahmad_assistant_stream(\"what is his date of birth?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e39cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tariq Ahmad is a detail‑oriented Python developer and aspiring machine‑learning engineer from Charsadda, Pakistan, currently pursuing a B.Sc. in Electrical and Computer Engineering at Pak‑Austria Fachhochschule. He has hands‑on experience building practical AI‑driven tools—such as a high‑performance data sampler, a background‑removal app, and a hybrid trading‑advisor—using Python, FastAPI, Azure, and various data‑science libraries. During a recent internship at the ATS AI Lab, he improved data‑preprocessing efficiency by about 30 % and boosted model prediction accuracy by roughly 15 % through optimized computer‑vision workflows. Tariq actively contributes to open‑source projects on GitHub, leads student‑welfare initiatives at his university, and enjoys exploring AI, cloud computing, and Linux system customization in his free time. He can be reached at +92 303 9383377 or via email at t.4hmad208@gmail.com.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tariq Ahmad is a detail‑oriented Python developer and aspiring machine‑learning engineer from Charsadda, Pakistan, currently pursuing a B.Sc. in Electrical and Computer Engineering at Pak‑Austria Fachhochschule. He has hands‑on experience building practical AI‑driven tools—such as a high‑performance data sampler, a background‑removal app, and a hybrid trading‑advisor—using Python, FastAPI, Azure, and various data‑science libraries. During a recent internship at the ATS AI Lab, he improved data‑preprocessing efficiency by about 30 % and boosted model prediction accuracy by roughly 15 % through optimized computer‑vision workflows. Tariq actively contributes to open‑source projects on GitHub, leads student‑welfare initiatives at his university, and enjoys exploring AI, cloud computing, and Linux system customization in his free time. He can be reached at +92 303 9383377 or via email at t.4hmad208@gmail.com."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(Tariq_Ahmad_assistant_stream(\"tell me about tariq in 5 sentenses ?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
